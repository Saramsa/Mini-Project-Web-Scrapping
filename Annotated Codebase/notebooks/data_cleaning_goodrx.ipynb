{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024df33d-c4dd-4cc2-b2e6-bca6c45a016a",
   "metadata": {},
   "source": [
    "### Function: `clean_goodrx_data`\n",
    "\n",
    "Cleans and standardizes the raw scraped GoodRx data for analysis.\n",
    "\n",
    "**Purpose:**\n",
    "- Remove formatting artifacts from pharmacy names.\n",
    "- Convert price columns to numeric values, handling missing or `\"N/A\"` entries.\n",
    "- Replace placeholder text (`\"N/A\"`) in drug-related columns with NaN.\n",
    "- Normalize special offer text to lowercase for consistency.\n",
    "- Flag online pharmacies based on keyword detection.\n",
    "- Map ZIP codes to corresponding city names for easier location-based analysis.\n",
    "\n",
    "**Parameters:**\n",
    "- `raw_csv_path` *(str)*: Path to the raw scraped CSV file.\n",
    "- `save_cleaned_csv_path` *(str, optional)*: If provided, saves the cleaned DataFrame to this path.\n",
    "\n",
    "**Returns:**\n",
    "- **DataFrame**: Cleaned dataset ready for analysis and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e54e08a-37da-47e1-97d6-66ed07318c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_goodrx_data(raw_csv_path, save_cleaned_csv_path=None):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # ZIP code to city mapping (update these as needed)\n",
    "    zip_to_city = {\n",
    "        '10001': 'New York',    # Manhattan, NY\n",
    "        '90001': 'Los Angeles', # LA, CA\n",
    "        '60601': 'Chicago',     # Chicago, IL\n",
    "        # Add more ZIPs and cities here if needed\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(raw_csv_path)\n",
    "\n",
    "    # All your previous cleaning steps ...\n",
    "    df['pharmacy'] = df['pharmacy'].str.replace('\\n', ' ', regex=True).str.strip()\n",
    "    price_columns = ['price', 'standard_coupon_price', 'special_coupon_price']\n",
    "    for col in price_columns:\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.replace('$', '', regex=False)\n",
    "            .replace({'N/A': np.nan, 'nan': np.nan})\n",
    "            .astype(float)\n",
    "        )\n",
    "    text_columns = ['drug', 'dosage', 'quantity']\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].replace('N/A', np.nan)\n",
    "    df = df.dropna(subset=['drug'])\n",
    "    df['special_offer'] = df['special_offer'].str.lower().str.strip()\n",
    "    df['online_pharmacy'] = df['pharmacy'].str.contains('pay online', case=False, na=False)\n",
    "\n",
    "    # --- NEW STEP: Assign city from ZIP code ---\n",
    "    # If your df has a column 'location' or 'zip', make sure to use the correct one!\n",
    "    # Here I'm using 'location' as the ZIP code column name. Update if needed.\n",
    "    df['zip_str'] = df['location'].astype(str).str.zfill(5)\n",
    "    df['city'] = df['zip_str'].map(zip_to_city)\n",
    "    df = df.drop(columns=['zip_str'])  # clean up helper col\n",
    "\n",
    "    # Save cleaned CSV\n",
    "    if save_cleaned_csv_path:\n",
    "        df.to_csv(save_cleaned_csv_path, index=False)\n",
    "        print(f\"Cleaned data saved to: {save_cleaned_csv_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2cdd7-8de3-4811-9ca3-d620f8b44a63",
   "metadata": {},
   "source": [
    "### Running the Data Cleaning Process\n",
    "\n",
    "This step calls the `clean_goodrx_data()` function to:\n",
    "1. Load the raw scraped data from `scraped_goodrx_data.csv`.\n",
    "2. Apply all cleaning and transformation steps (price formatting, missing value handling, city mapping, etc.).\n",
    "3. Save the cleaned dataset as `goodrx_cleaned_data.csv` for use in further analysis.\n",
    "4. Store the cleaned DataFrame in `cleaned_df` for immediate in-notebook use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707dddcf-2cb1-4009-a166-2ad8c8d029f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: goodrx_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_df = clean_goodrx_data(\n",
    "    raw_csv_path='scraped_goodrx_data.csv',\n",
    "    save_cleaned_csv_path='goodrx_cleaned_data.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f95feb-6b01-4fd6-8749-ec4069353ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
